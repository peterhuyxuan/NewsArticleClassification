{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming training set words to features with TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9500, 35822)\n",
      "0        5\n",
      "1        7\n",
      "2       10\n",
      "3        5\n",
      "4        0\n",
      "        ..\n",
      "9495     3\n",
      "9496     0\n",
      "9497     5\n",
      "9498     0\n",
      "9499     5\n",
      "Name: topic, Length: 9500, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import csv\n",
    "\n",
    "df=pd.read_csv('training.csv')\n",
    "\n",
    "cleanup_nums = {\"topic\": {\"IRRELEVANT\": 0, \"ARTS CULTURE ENTERTAINMENT\": 1, \"BIOGRAPHIES PERSONALITIES PEOPLE\": 2, \"DEFENCE\": 3, \"DOMESTIC MARKETS\": 4,\n",
    "                                  \"FOREX MARKETS\": 5, \"HEALTH\": 6, \"MONEY MARKETS\": 7, \"SCIENCE AND TECHNOLOGY\": 8, \"SHARE LISTINGS\": 9, \"SPORTS\":10 }}\n",
    "\n",
    "\n",
    "df.replace(cleanup_nums, inplace=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#give each word a tf-idf value\n",
    "train_features = vectorizer.fit_transform(df['article_words'])\n",
    "\n",
    "print(train_features.shape)\n",
    "\n",
    "y_train = df['topic']\n",
    "\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming test set words to features with TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 35822)\n",
      "0       0\n",
      "1       0\n",
      "2       5\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "495     0\n",
      "496    10\n",
      "497     7\n",
      "498     9\n",
      "499     0\n",
      "Name: topic, Length: 500, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv('test.csv')\n",
    "\n",
    "cleanup_nums = {\"topic\": {\"IRRELEVANT\": 0, \"ARTS CULTURE ENTERTAINMENT\": 1, \"BIOGRAPHIES PERSONALITIES PEOPLE\": 2, \"DEFENCE\": 3, \"DOMESTIC MARKETS\": 4,\n",
    "                                  \"FOREX MARKETS\": 5, \"HEALTH\": 6, \"MONEY MARKETS\": 7, \"SCIENCE AND TECHNOLOGY\": 8, \"SHARE LISTINGS\": 9, \"SPORTS\":10 }}\n",
    "\n",
    "\n",
    "df_test.replace(cleanup_nums, inplace=True)\n",
    "\n",
    "#give each word a tf-idf value\n",
    "test_features = vectorizer.transform(df_test['article_words'])\n",
    "\n",
    "print(test_features.shape)\n",
    "\n",
    "y_test = df_test['topic']\n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run ML algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0 10  0  0  0  0 10 10  0  7  0  0  0 10  0  0  0  0\n",
      "  7  0  0  7  7  7  0  0  0  7  0 10  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  7  7  0  0  0  7  0  0  0  0  7  0  0  0  0  7  0  0 10 10  7  0  0\n",
      " 10 10  0  0  0  0  0  0  0  0  0  0  0  7  0  7  0  0  0  0  0  0  0 10\n",
      " 10  0  0  0  0  0  0  0  0  0  0 10  0 10  0  0  0  0  0  0  0  7  0 10\n",
      "  0  0  0  0  0  0  0  0  0 10  0  0  0  7  0  0  0  7  0  0  7  0  0  0\n",
      "  0  0  0  0  0  7  0  0 10  0  0  0  0  0  0  0  0 10 10  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  7  0  0  0  7  0  0  0  0  0  0  0  0  0  0\n",
      "  0 10 10  0  0  0  0  0  0  7  0  0  0  0  7  7  0  0  0  0  0  0  0  0\n",
      "  0  7  0  0  0  0  0  0  7  0  0  0  0  0  0  0  7  0  0  0  7 10  0  7\n",
      "  0  0  0  0  0  0  0  7  0  0  0 10  0 10  7  0  0  0  0 10  7  0 10  0\n",
      "  7  7  0  0  7  0  0  7  0 10  0  7  0  0  0  0  0 10  0  0  0  0 10  0\n",
      "  0  0 10  0  0  0  0  0  0  7  0 10  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 10  0  0  0  0 10  0  7 10  7  0  7  0  7  0  7  0  0  0 10  0  0  7 10\n",
      "  7  0  0  0  0  0  0  0  0  0  0 10  0  0  0  7  7  0  7  0 10 10  0  7\n",
      "  0  0  7  0  0  7  0  0  7  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0 10  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  7  0  0 10 10  0 10  0  7  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  7  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  7  0  0 10  0  0  7  0  0  0  0  0  0  0  7  0  7  0 10  0\n",
      " 10  0  0  7  0  7  0  0  0  0  0 10  0  0  7  0 10  7  0  0]\n",
      "[ 0  0  7  0  0  0  0 10  0  0  0  0 10 10  0  7  0  0  0 10  0  0  0  0\n",
      "  5  0  0  0  7  7  5  0  0  7  0 10  0  0  7  0 10  0  0  0  0  0  7  5\n",
      "  0  5  7  0  7  0  7  0  0  0  3  7  0  0  0  0  7  0  0 10 10  7  7  0\n",
      " 10 10  0  3  0  0  0 10  0 10  7  7  0  7  7  5  0  0  0  0  0  7  0 10\n",
      " 10  0  0  7  0  7  0  0  0  0  0 10  0 10  0  0  0  0  0  0  0  7  0 10\n",
      "  0  0  0  0  7  0  7  0  0 10  0  0  0  7  0  0  0  7  0  0  5  0  0  0\n",
      "  0  0  0  0  0  7  0  0 10  0  0 10 10  0  7  0  0 10 10  0  0  0  0  0\n",
      "  0  0  7  7  0  0  0  7  0  7  0  0  0  5  7  0  0  0  0  0  0  0  7  0\n",
      "  0 10 10  0  0  0  0  0  0  7  0  7  0  0  7  7  0  0  0  0  0  0  0  0\n",
      "  0  7  0  0  0  0  7  0  7  0  0  0  5  0  0  0  7  7  0 10  7 10  0  7\n",
      "  0  0  7  0  0  0  0  7  0  0  0 10  0 10  7  0 10  0  0 10  7  0 10  0\n",
      "  7  7  0  0  7  0  0  7  0 10  0  7  0  0  0  0  0 10  0  0  0  5 10  0\n",
      "  0  0 10  0  0  0  0  0  0  5  0 10 10  0  0  0  0  0  0  7 10  0 10  0\n",
      " 10  0  0  0 10  0  0  7  0  7  7  7  0  7  0  7  0 10  0 10  0  0  7 10\n",
      "  7  0  0  7  0  0  0  0  7  0  0 10 10  0  7  7  7  0  7  0 10 10  0  7\n",
      "  0  0  7  0  0  7  0  0  7  0  7  0  0  0  7  0  0  0  0  0  0  0  0  0\n",
      "  0 10  0  0  5  0  0  0  0  7  0  0  0  7  0  0  7  7  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  7  0  0 10 10  0 10  0  7  0  0  0  0  0  0 10  0\n",
      "  0  0  0  0  0  0  7  0  0 10  0  7  0  0  0  0  0  0  0  1  0  0  0  0\n",
      "  0  0  0  0  7  0  7 10  7  0  7  0  0  0  0  0  0  0  7  0  5  0 10  0\n",
      " 10  6  0  5  0  5  0 10  0  7  0 10  0  0  7  0 10  7  0  0]\n"
     ]
    }
   ],
   "source": [
    "#naive bayes rule\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NBclf = MultinomialNB()\n",
    "\n",
    "NBclf.fit(train_features, y_train)\n",
    "\n",
    "NBpredictions = NBclf.predict(test_features)\n",
    "\n",
    "#prints the NB topic predicitions of the test data\n",
    "print(NBpredictions)\n",
    "\n",
    "\n",
    "#random forst\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFclf = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "\n",
    "\n",
    "RFclf.fit(train_features, y_train)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "RFpredictions = RFclf.predict(test_features)\n",
    "\n",
    "\n",
    "#prints the RF topic predicitions of the test data\n",
    "print(RFpredictions)\n",
    "\n",
    "\n",
    "\n",
    "# # Calculate the absolute errors\n",
    "# errors = abs(predictions - y_test)\n",
    "\n",
    "# # Print out the mean absolute error (mae)\n",
    "# print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
