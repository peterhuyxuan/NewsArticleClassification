{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming training set words to features with TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9500, 35822)\n",
      "0       FOREX MARKETS\n",
      "1       MONEY MARKETS\n",
      "2              SPORTS\n",
      "3       FOREX MARKETS\n",
      "4          IRRELEVANT\n",
      "            ...      \n",
      "9495          DEFENCE\n",
      "9496       IRRELEVANT\n",
      "9497    FOREX MARKETS\n",
      "9498       IRRELEVANT\n",
      "9499    FOREX MARKETS\n",
      "Name: topic, Length: 9500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv('training.csv')\n",
    "\n",
    "# cleanup_nums = {\"topic\": {\"IRRELEVANT\": 0, \"ARTS CULTURE ENTERTAINMENT\": 1, \"BIOGRAPHIES PERSONALITIES PEOPLE\": 2, \"DEFENCE\": 3, \"DOMESTIC MARKETS\": 4,\n",
    "#                                   \"FOREX MARKETS\": 5, \"HEALTH\": 6, \"MONEY MARKETS\": 7, \"SCIENCE AND TECHNOLOGY\": 8, \"SHARE LISTINGS\": 9, \"SPORTS\":10 }}\n",
    "\n",
    "\n",
    "# df.replace(cleanup_nums, inplace=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#give each word a tf-idf value\n",
    "train_features = vectorizer.fit_transform(df['article_words'])\n",
    "\n",
    "print(train_features.shape)\n",
    "\n",
    "y_train = df['topic']\n",
    "\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming test set words to features with TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 35822)\n",
      "0          IRRELEVANT\n",
      "1          IRRELEVANT\n",
      "2       FOREX MARKETS\n",
      "3          IRRELEVANT\n",
      "4          IRRELEVANT\n",
      "            ...      \n",
      "495        IRRELEVANT\n",
      "496            SPORTS\n",
      "497     MONEY MARKETS\n",
      "498    SHARE LISTINGS\n",
      "499        IRRELEVANT\n",
      "Name: topic, Length: 500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv('test.csv')\n",
    "\n",
    "# cleanup_nums = {\"topic\": {\"IRRELEVANT\": 0, \"ARTS CULTURE ENTERTAINMENT\": 1, \"BIOGRAPHIES PERSONALITIES PEOPLE\": 2, \"DEFENCE\": 3, \"DOMESTIC MARKETS\": 4,\n",
    "#                                   \"FOREX MARKETS\": 5, \"HEALTH\": 6, \"MONEY MARKETS\": 7, \"SCIENCE AND TECHNOLOGY\": 8, \"SHARE LISTINGS\": 9, \"SPORTS\":10 }}\n",
    "\n",
    "\n",
    "# df_test.replace(cleanup_nums, inplace=True)\n",
    "\n",
    "#give each word a tf-idf value\n",
    "test_features = vectorizer.transform(df_test['article_words'])\n",
    "\n",
    "print(test_features.shape)\n",
    "\n",
    "y_test = df_test['topic']\n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run ML algos\n",
    "\n",
    "Naive Bayes Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #naive bayes rule\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# NBclf = MultinomialNB()\n",
    "\n",
    "# NBclf.fit(train_features, y_train)\n",
    "\n",
    "# #gets the NB topic predicitions of the test data\n",
    "# NBpredictions = NBclf.predict(test_features)\n",
    "\n",
    "# np.mean(NBpredictions == y_test)\n",
    "\n",
    "# #tuning\n",
    "\n",
    "# # from sklearn.model_selection import GridSearchCV\n",
    "# # gs_clf = GridSearchCV(NBclf, parameters, n_jobs=-1)\n",
    "# # gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# RFclf = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "parameters = {\n",
    "                'n_estimators': [50, 150],\n",
    "                'bootstrap': (True, False), \n",
    "                'max_features': ('auto', 'sqrt', 'log2', None)\n",
    "             }\n",
    "rf = RandomForestClassifier()\n",
    "RFclf = GridSearchCV(rf, parameters)\n",
    "RFclf.fit(train_features, y_train)\n",
    "\n",
    "pd.DataFrame(RFclf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "RFpredictions = RFclf.predict(test_features)\n",
    "\n",
    "np.mean(RFpredictions == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# SVM_clf = SVC(kernel='linear')\n",
    "# SVM_clf.fit(train_features, y_train)\n",
    "# SVMpredictions = SVM_clf.predict(test_features)\n",
    "\n",
    "\n",
    "# print(\"hello\")\n",
    "# np.mean(SVMpredictions == y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# LGR_clf = LogisticRegression(random_state=0)\n",
    "# LGR_clf.fit(train_features, y_train)\n",
    "# LGR_prediction = LGR_clf.predict(test_features)\n",
    "\n",
    "# np.mean(LGR_prediction == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# SGD_clf = linear_model.SGDClassifier(tol=1e-2, shuffle=False, learning_rate='constant', eta0=1)\n",
    "# SGD_clf.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD_prediction = SGD_clf.predict(test_features)\n",
    "# np.mean(SGD_prediction == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "clf_sigmoid = CalibratedClassifierCV(RFclf, cv='prefit', method='sigmoid')\n",
    "clf_sigmoid.fit(train_features, y_train)\n",
    "\n",
    "target_names = [\"ARTS CULTURE ENTERTAINMENT\", \"BIOGRAPHIES PERSONALITIES PEOPLE\", \"DEFENCE\", \"DOMESTIC MARKETS\", \"FOREX MARKETS\", \"HEALTH\", \"IRRELEVANT\", \"MONEY MARKETS\", \"SCIENCE AND TECHNOLOGY\", \"SHARE LISTINGS\", \"SPORTS\"] \n",
    "\n",
    "\n",
    "pd.DataFrame(clf_sigmoid.predict_proba(test_features)*100, columns=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba=list(map(list,zip(*(clf_sigmoid.predict_proba(test_features)*100))))\n",
    "tempsort=[]\n",
    "psort=[[],[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "for i in range(11):\n",
    "    keys=list(range(9501, 10001))\n",
    "    tempsort.append(sorted(list(zip(keys,proba[i])), key=lambda x: x[1], reverse=True))\n",
    "    tempsort[i]=tempsort[i][:10]\n",
    "    for j in tempsort[i]:\n",
    "        if RFpredictions[j[0] - 9501] == target_names[i]:\n",
    "            psort[i].append(j)\n",
    "    display(pd.DataFrame(psort[i], columns=[\"Article\",target_names[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, RFpredictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------BELOW IS NOT SUPER NEEDED DELETE LATER-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"training.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['topic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "df3 = df2[['topic','article_words']]\n",
    "df3.groupby('topic').count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADJUST LATER\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labels = df3['topic']\n",
    "text = df['article_words']\n",
    "\n",
    "# ADJUST LATER\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, labels, random_state=0, test_size=0.3)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tf_transformer = TfidfTransformer().fit(X_train_counts)\n",
    "X_train_transformed = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_transformed = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "labels = LabelEncoder()\n",
    "y_train_labels_fit = labels.fit(y_train)\n",
    "y_train_lables_trf = labels.transform(y_train)\n",
    "\n",
    "print(labels.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "linear_svc = linear_model.SGDClassifier(max_iter=1500, tol=1e-3)\n",
    "clf = linear_svc.fit(X_train_transformed,y_train_lables_trf)\n",
    "\n",
    "calibrated_svc = CalibratedClassifierCV(base_estimator=linear_svc,\n",
    "                                        cv=\"prefit\")\n",
    "\n",
    "calibrated_svc.fit(X_train_transformed,y_train_lables_trf)\n",
    "predicted = calibrated_svc.predict(X_test_transformed)\n",
    "\n",
    "# Need to update\n",
    "to_predict = [\"I have outdated information on my credit report that I have previously disputed that has yet to be removed this information is more then seven years old and does not meet credit reporting requirements\"]\n",
    "p_count = count_vect.transform(to_predict)\n",
    "p_tfidf = tf_transformer.transform(p_count)\n",
    "print('Average accuracy on test set={}'.format(np.mean(predicted == labels.transform(y_test))))\n",
    "print('Predicted probabilities of demo input string are')\n",
    "print(calibrated_svc.predict_proba(p_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(calibrated_svc.predict_proba(p_tfidf)*100, columns=labels.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
