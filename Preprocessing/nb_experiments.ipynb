{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('training.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "y_train = training_df['topic']\n",
    "y_test = test_df['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35823\n",
      "[2.38405306e-02 1.17232812e-03 5.92409583e-02 ... 0.00000000e+00\n",
      " 3.99161691e-05 3.99161691e-05]\n",
      "[0.01891437 0.00069765 0.05654598 ... 0.         0.         0.        ]\n",
      "[0.02549916 0.00128358 0.00746048 ... 0.         0.         0.        ]\n",
      "[7.63176384e-03 5.42080874e-04 2.31130935e-02 ... 2.59036476e-05\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "[0.00783205 0.         0.01235197 ... 0.         0.         0.        ]\n",
      "[0.00885717 0.00061149 0.01725865 ... 0.         0.         0.        ]\n",
      "[0.00167749 0.00025989 0.0063773  ... 0.         0.         0.        ]\n",
      "[0.00936375 0.00098046 0.012028   ... 0.         0.         0.        ]\n",
      "[0.0129255  0.         0.01757448 ... 0.         0.         0.        ]\n",
      "[0.004762   0.00035784 0.01321229 ... 0.         0.         0.        ]\n",
      "[0.01181187 0.00057624 0.0091316  ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#custom vectorize\n",
    "#naive scorer model...not really probabilities but class dependent score\n",
    "corpus_indexer = {}\n",
    "corpus_index = 0\n",
    "for sentence in training_df['article_words']:\n",
    "    words = sentence.split(',')\n",
    "    for word in words:\n",
    "        if word not in corpus_indexer:\n",
    "            corpus_indexer[word] = corpus_index\n",
    "            corpus_index += 1\n",
    "\n",
    "print(corpus_index)\n",
    "\n",
    "#probably dont need this intermediate step/datastructure\n",
    "class_data = {}\n",
    "for row in training_df.itertuples():\n",
    "    words = row.article_words.split(',')\n",
    "    topic = row.topic\n",
    "    if topic not in class_data:\n",
    "        class_data[topic] = []\n",
    "    doc_vector = np.zeros((corpus_index))\n",
    "    for word in words:\n",
    "        index = corpus_indexer[word]\n",
    "        doc_vector[index] += 1\n",
    "    class_data[topic].append(doc_vector)\n",
    "\n",
    "#do numpy stuff\n",
    "for topic, matrix in class_data.items():\n",
    "    matrix = np.vstack(matrix)\n",
    "    matrix = matrix/np.linalg.norm(matrix, axis=1, keepdims=True)\n",
    "    class_data[topic] = matrix.mean(0)\n",
    "    \n",
    "for topic, vector in class_data.items():\n",
    "    print(vector)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636\n"
     ]
    }
   ],
   "source": [
    "def my_vectorizer(words, indexer, size):\n",
    "    vec = np.zeros((size))\n",
    "    for word in words:\n",
    "        if word not in indexer: continue\n",
    "        index = indexer[word]\n",
    "        vec[index] += 1\n",
    "    return vec/np.linalg.norm(vec, keepdims=True)\n",
    "\n",
    "def my_classify(model, vec):\n",
    "    classes = list(model.keys())\n",
    "    num_classes = len(classes)\n",
    "    vals = np.zeros((num_classes))\n",
    "    for i, k in enumerate(classes):\n",
    "        model_vec = model[k]\n",
    "        vals[i] = np.sqrt(np.mean((model_vec-vec)**2))\n",
    "    c = np.argmin(vals)\n",
    "    return classes[c]\n",
    "\n",
    "def accuracy(preds, true):\n",
    "    size = len(preds)\n",
    "    total = 0\n",
    "    for i, v in enumerate(true):\n",
    "        if preds[i] == v: total += 1\n",
    "    return total/size\n",
    "\n",
    "preds = []\n",
    "for sentence in test_df['article_words']:\n",
    "    words = sentence.split(',')\n",
    "    vec = my_vectorizer(words, corpus_indexer, corpus_index)\n",
    "    preds.append(my_classify(class_data, vec))\n",
    "\n",
    "acc = accuracy(preds, test_df['topic'])\n",
    "print(acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n"
     ]
    }
   ],
   "source": [
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642\n"
     ]
    }
   ],
   "source": [
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646\n"
     ]
    }
   ],
   "source": [
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636\n"
     ]
    }
   ],
   "source": [
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,5))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.554\n"
     ]
    }
   ],
   "source": [
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(10,10))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728\n"
     ]
    }
   ],
   "source": [
    "#might be good to get rid of irrelevant class...bias towards it especially since large class\n",
    "#term or document frequency?\n",
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = CountVectorizer()\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,5))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB(fit_prior=False)\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.736\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB(fit_prior=False)\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB(fit_prior=False)\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), use_idf=False, sublinear_tf=True)\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work still needs to be done with the actual feature metric being used some combination of its frequency within a document and the differentiability of that word in a class compared to others...that might be what feature selection does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using feature selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
