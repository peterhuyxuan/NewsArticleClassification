{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('training.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "y_train = training_df['topic']\n",
    "y_test = test_df['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'vect__min_df': (1, 5, 11), 'vect__max_df': (0.75, 0.85, 1.0), 'vect__max_features': (None, 5000, 10000), 'vect__ngram_range': ((1, 1), (1, 3), (2, 3), (3, 6)), 'tfidf__use_idf': (True, False), 'tfidf__sublinear_tf': [True], 'clf__fit_prior': (True, False)}\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 74.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 112.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 159.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed: 187.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 11234.100s\n",
      "\n",
      "Best score: 0.748\n",
      "Best parameters set:\n",
      "\tclf__fit_prior: False\n",
      "\ttfidf__sublinear_tf: True\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: None\n",
      "\tvect__min_df: 5\n",
      "\tvect__ngram_range: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    #'vect__min_df': (1, 3, 5, 11, 17, 31),\n",
    "    'vect__min_df': (1, 5, 11),\n",
    "    'vect__max_df': (0.75, 0.85, 1.0),\n",
    "    #'vect__max_df': (0.65, 0.75, 0.85, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000),\n",
    "    #'vect__max_features': (None, 5000, 10000, 15000, 25000),\n",
    "    'vect__ngram_range': ((1, 1), (1,3), (2,3), (3,6)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__sublinear_tf': [True],\n",
    "    #'tfidf__sublinear_tf': (True, False),\n",
    "    # 'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__fit_prior': (True, False)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(training_df['article_words'], training_df['topic'])\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752\n"
     ]
    }
   ],
   "source": [
    "#preds = grid_search.predict(test_df['article_words'])\n",
    "acc = grid_search.score(test_df['article_words'], test_df['topic'])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestimator = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(2,3), max_df=0.75, min_df=5, max_features=None)),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True, sublinear_tf=True)),\n",
    "    ('clf', MultinomialNB(fit_prior=False)),\n",
    "])\n",
    "bestimator.fit(training_df['article_words'], training_df['topic'])\n",
    "print(bestimator.score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35823\n",
      "[2.38405306e-02 1.17232812e-03 5.92409583e-02 ... 0.00000000e+00\n",
      " 3.99161691e-05 3.99161691e-05]\n",
      "[0.01891437 0.00069765 0.05654598 ... 0.         0.         0.        ]\n",
      "[0.02549916 0.00128358 0.00746048 ... 0.         0.         0.        ]\n",
      "[7.63176384e-03 5.42080874e-04 2.31130935e-02 ... 2.59036476e-05\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "[0.00783205 0.         0.01235197 ... 0.         0.         0.        ]\n",
      "[0.00885717 0.00061149 0.01725865 ... 0.         0.         0.        ]\n",
      "[0.00167749 0.00025989 0.0063773  ... 0.         0.         0.        ]\n",
      "[0.00936375 0.00098046 0.012028   ... 0.         0.         0.        ]\n",
      "[0.0129255  0.         0.01757448 ... 0.         0.         0.        ]\n",
      "[0.004762   0.00035784 0.01321229 ... 0.         0.         0.        ]\n",
      "[0.01181187 0.00057624 0.0091316  ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#custom vectorize\n",
    "#naive scorer model...not really probabilities but class dependent score\n",
    "corpus_indexer = {}\n",
    "corpus_index = 0\n",
    "for sentence in training_df['article_words']:\n",
    "    words = sentence.split(',')\n",
    "    for word in words:\n",
    "        if word not in corpus_indexer:\n",
    "            corpus_indexer[word] = corpus_index\n",
    "            corpus_index += 1\n",
    "\n",
    "print(corpus_index)\n",
    "\n",
    "#probably dont need this intermediate step/datastructure\n",
    "class_data = {}\n",
    "for row in training_df.itertuples():\n",
    "    words = row.article_words.split(',')\n",
    "    topic = row.topic\n",
    "    if topic not in class_data:\n",
    "        class_data[topic] = []\n",
    "    doc_vector = np.zeros((corpus_index))\n",
    "    for word in words:\n",
    "        index = corpus_indexer[word]\n",
    "        doc_vector[index] += 1\n",
    "    class_data[topic].append(doc_vector)\n",
    "\n",
    "#do numpy stuff\n",
    "for topic, matrix in class_data.items():\n",
    "    matrix = np.vstack(matrix)\n",
    "    matrix = matrix/np.linalg.norm(matrix, axis=1, keepdims=True)\n",
    "    class_data[topic] = matrix.mean(0)\n",
    "    \n",
    "for topic, vector in class_data.items():\n",
    "    print(vector)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636\n"
     ]
    }
   ],
   "source": [
    "def my_vectorizer(words, indexer, size):\n",
    "    vec = np.zeros((size))\n",
    "    for word in words:\n",
    "        if word not in indexer: continue\n",
    "        index = indexer[word]\n",
    "        vec[index] += 1\n",
    "    return vec/np.linalg.norm(vec, keepdims=True)\n",
    "\n",
    "def my_classify(model, vec):\n",
    "    classes = list(model.keys())\n",
    "    num_classes = len(classes)\n",
    "    vals = np.zeros((num_classes))\n",
    "    for i, k in enumerate(classes):\n",
    "        model_vec = model[k]\n",
    "        vals[i] = np.sqrt(np.mean((model_vec-vec)**2))\n",
    "    c = np.argmin(vals)\n",
    "    return classes[c]\n",
    "\n",
    "def accuracy(preds, true):\n",
    "    size = len(preds)\n",
    "    total = 0\n",
    "    for i, v in enumerate(true):\n",
    "        if preds[i] == v: total += 1\n",
    "    return total/size\n",
    "\n",
    "preds = []\n",
    "for sentence in test_df['article_words']:\n",
    "    words = sentence.split(',')\n",
    "    vec = my_vectorizer(words, corpus_indexer, corpus_index)\n",
    "    preds.append(my_classify(class_data, vec))\n",
    "\n",
    "acc = accuracy(preds, test_df['topic'])\n",
    "print(acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n"
     ]
    }
   ],
   "source": [
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642\n"
     ]
    }
   ],
   "source": [
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646\n"
     ]
    }
   ],
   "source": [
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636\n"
     ]
    }
   ],
   "source": [
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,5))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.554\n"
     ]
    }
   ],
   "source": [
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(10,10))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728\n"
     ]
    }
   ],
   "source": [
    "#might be good to get rid of irrelevant class...bias towards it especially since large class\n",
    "#term or document frequency?\n",
    "#a bit confused how test data is transformed...is term frequency within a doc calculated for test data\n",
    "vectorizer = CountVectorizer()\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,5))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB(fit_prior=False)\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.736\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB(fit_prior=False)\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB(fit_prior=False)\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), use_idf=False, sublinear_tf=True)\n",
    "train_features = vectorizer.fit_transform(training_df['article_words'])\n",
    "test_features = vectorizer.transform(test_df['article_words'])\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, y_train)\n",
    "predictions = classifier.predict(test_features)\n",
    "acc = np.mean(predictions == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work still needs to be done with the actual feature metric being used some combination of its frequency within a document and the differentiability of that word in a class compared to others...that might be what feature selection does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using feature selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
