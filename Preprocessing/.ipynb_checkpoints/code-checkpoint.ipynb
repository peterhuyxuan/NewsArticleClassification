{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming training set words to features with TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9500, 35822)\n",
      "0       FOREX MARKETS\n",
      "1       MONEY MARKETS\n",
      "2              SPORTS\n",
      "3       FOREX MARKETS\n",
      "4          IRRELEVANT\n",
      "            ...      \n",
      "9495          DEFENCE\n",
      "9496       IRRELEVANT\n",
      "9497    FOREX MARKETS\n",
      "9498       IRRELEVANT\n",
      "9499    FOREX MARKETS\n",
      "Name: topic, Length: 9500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv('training.csv')\n",
    "\n",
    "# cleanup_nums = {\"topic\": {\"IRRELEVANT\": 0, \"ARTS CULTURE ENTERTAINMENT\": 1, \"BIOGRAPHIES PERSONALITIES PEOPLE\": 2, \"DEFENCE\": 3, \"DOMESTIC MARKETS\": 4,\n",
    "#                                   \"FOREX MARKETS\": 5, \"HEALTH\": 6, \"MONEY MARKETS\": 7, \"SCIENCE AND TECHNOLOGY\": 8, \"SHARE LISTINGS\": 9, \"SPORTS\":10 }}\n",
    "\n",
    "\n",
    "# df.replace(cleanup_nums, inplace=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#give each word a tf-idf value\n",
    "train_features = vectorizer.fit_transform(df['article_words'])\n",
    "\n",
    "print(train_features.shape)\n",
    "\n",
    "y_train = df['topic']\n",
    "\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming test set words to features with TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 35822)\n",
      "0          IRRELEVANT\n",
      "1          IRRELEVANT\n",
      "2       FOREX MARKETS\n",
      "3          IRRELEVANT\n",
      "4          IRRELEVANT\n",
      "            ...      \n",
      "495        IRRELEVANT\n",
      "496            SPORTS\n",
      "497     MONEY MARKETS\n",
      "498    SHARE LISTINGS\n",
      "499        IRRELEVANT\n",
      "Name: topic, Length: 500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv('test.csv')\n",
    "\n",
    "# cleanup_nums = {\"topic\": {\"IRRELEVANT\": 0, \"ARTS CULTURE ENTERTAINMENT\": 1, \"BIOGRAPHIES PERSONALITIES PEOPLE\": 2, \"DEFENCE\": 3, \"DOMESTIC MARKETS\": 4,\n",
    "#                                   \"FOREX MARKETS\": 5, \"HEALTH\": 6, \"MONEY MARKETS\": 7, \"SCIENCE AND TECHNOLOGY\": 8, \"SHARE LISTINGS\": 9, \"SPORTS\":10 }}\n",
    "\n",
    "\n",
    "# df_test.replace(cleanup_nums, inplace=True)\n",
    "\n",
    "#give each word a tf-idf value\n",
    "test_features = vectorizer.transform(df_test['article_words'])\n",
    "\n",
    "print(test_features.shape)\n",
    "\n",
    "y_test = df_test['topic']\n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run ML algos\n",
    "\n",
    "Naive Bayes Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#naive bayes rule\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NBclf = MultinomialNB()\n",
    "\n",
    "NBclf.fit(train_features, y_train)\n",
    "\n",
    "#gets the NB topic predicitions of the test data\n",
    "NBpredictions = NBclf.predict(test_features)\n",
    "\n",
    "np.mean(NBpredictions == y_test)\n",
    "\n",
    "#tuning\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# gs_clf = GridSearchCV(NBclf, parameters, n_jobs=-1)\n",
    "# gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.728"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFclf = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "\n",
    "\n",
    "RFclf.fit(train_features, y_train)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "RFpredictions = RFclf.predict(test_features)\n",
    "\n",
    "np.mean(RFpredictions == y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM_clf = SVC(kernel='linear')\n",
    "SVM_clf.fit(train_features, y_train)\n",
    "SVMpredictions = SVM_clf.predict(test_features)\n",
    "\n",
    "\n",
    "print(\"hello\")\n",
    "np.mean(SVMpredictions == y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_word_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bfcacee8a378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m train_embedding_weights = np.zeros((len(train_word_index)+1, \n\u001b[0m\u001b[1;32m     33\u001b[0m  EMBEDDING_DIM))\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_word_index' is not defined"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "def ConvNet(embeddings, max_sequence_length, num_words, embedding_dim, labels_index):\n",
    " \n",
    "    embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            weights=[embeddings],\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=False)\n",
    "    \n",
    "    sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    convs = []\n",
    "    filter_sizes = [2,3,4,5,6]\n",
    "    for filter_size in filter_sizes:\n",
    "        l_conv = Conv1D(filters=200, \n",
    "                        kernel_size=filter_size, \n",
    "                        activation='relu')(embedded_sequences)\n",
    "        l_pool = GlobalMaxPooling1D()(l_conv)\n",
    "        convs.append(l_pool)\n",
    "    l_merge = concatenate(convs, axis=1)\n",
    "    x = Dropout(0.1)(l_merge)  \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    preds = Dense(labels_index, activation='sigmoid')(x)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "train_embedding_weights = np.zeros((len(train_word_index)+1, \n",
    "                                    EMBEDDING_DIM))\n",
    "\n",
    "model = ConvNet(train_embedding_weights, \n",
    "                MAX_SEQUENCE_LENGTH, \n",
    "                len(train_word_index)+1, \n",
    "                EMBEDDING_DIM, len(list(label_names)))\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 32\n",
    "hist = model.fit(x_train, \n",
    "                 y_tr, \n",
    "                 epochs=num_epochs, \n",
    "                 validation_split=0.1, \n",
    "                 shuffle=True, \n",
    "                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                      IRRELEVANT       1.00      0.33      0.50         3\n",
      "      ARTS CULTURE ENTERTAINMENT       0.00      0.00      0.00        15\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       1.00      0.23      0.38        13\n",
      "                         DEFENCE       0.00      0.00      0.00         2\n",
      "                DOMESTIC MARKETS       0.46      0.12      0.20        48\n",
      "                   FOREX MARKETS       0.00      0.00      0.00        14\n",
      "                          HEALTH       0.76      0.94      0.84       266\n",
      "                   MONEY MARKETS       0.54      0.74      0.63        69\n",
      "          SCIENCE AND TECHNOLOGY       0.00      0.00      0.00         3\n",
      "                  SHARE LISTINGS       1.00      0.14      0.25         7\n",
      "                          SPORTS       0.91      0.88      0.90        60\n",
      "\n",
      "                        accuracy                           0.73       500\n",
      "                       macro avg       0.52      0.31      0.34       500\n",
      "                    weighted avg       0.68      0.73      0.68       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jingj\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = [\"IRRELEVANT\", \"ARTS CULTURE ENTERTAINMENT\", \"BIOGRAPHIES PERSONALITIES PEOPLE\", \"DEFENCE\", \"DOMESTIC MARKETS\", \"FOREX MARKETS\", \"HEALTH\", \"MONEY MARKETS\", \"SCIENCE AND TECHNOLOGY\", \"SHARE LISTINGS\", \"SPORTS\"] \n",
    "\n",
    "print(classification_report(y_test, RFpredictions, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
