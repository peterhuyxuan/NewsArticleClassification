{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_dev(distr, avg, num_samples):\n",
    "    sum_of_squares = 0\n",
    "    for k,v in distr.items():\n",
    "        sum_of_squares += v*((k-avg)**2)\n",
    "    variance = sum_of_squares/num_samples\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('training.csv')\n",
    "training_df.drop('article_number', axis=1, inplace=True)\n",
    "print(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = training_df['topic']\n",
    "label_distr = labels.value_counts()\n",
    "print(label_distr)\n",
    "print(label_distr.shape)\n",
    "print(label_distr['IRRELEVANT'])\n",
    "label_sum = label_distr.sum()\n",
    "print(label_sum)\n",
    "label_distr = pd.concat([pd.Series(data=[label_sum], index=['global']), label_distr])\n",
    "print(label_distr)\n",
    "print(label_distr['DEFENCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = {'global':{}}\n",
    "\n",
    "for row in training_df.itertuples():\n",
    "    sentence = row.article_words\n",
    "    sentence = sentence.split(sep=',')\n",
    "    words = len(sentence)\n",
    "    if words not in distr['global']:\n",
    "        distr['global'][words] = 0\n",
    "    distr['global'][words] += 1\n",
    "    #get label counts from dataframe\n",
    "#     if 'count' not in distr['global']:\n",
    "#         distr['global']['count'] = 0\n",
    "#     distr['global']['count'] += 1\n",
    "    if 'total' not in distr['global']:\n",
    "        distr['global']['total'] = 0\n",
    "    distr['global']['total'] += words\n",
    "    #topic = row.topic.lower()\n",
    "    topic = row.topic\n",
    "    if topic not in distr:\n",
    "        distr[topic] = {}\n",
    "    if words not in distr[topic]:\n",
    "        distr[topic][words] = 0\n",
    "    distr[topic][words] += 1\n",
    "    if 'total' not in distr[topic]:\n",
    "        distr[topic]['total'] = 0\n",
    "    distr[topic]['total'] += words\n",
    "\n",
    "print(distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##messy as hell\n",
    "print('text length statistics')\n",
    "for label, lengths in distr.items():\n",
    "    num_samples = label_distr[label]\n",
    "    avg = lengths['total']/num_samples\n",
    "    del lengths['total'] #total should be separate...not in the distr data...classes might be easier\n",
    "    filtered_lengths = [x for x in lengths.keys() if isinstance(x, int)]\n",
    "    #print(filtered_lengths)\n",
    "    deviation = std_dev(lengths, avg, num_samples)\n",
    "    min_len = min(filtered_lengths)\n",
    "    max_len = max(filtered_lengths)\n",
    "    freqs = [v for k,v in lengths.items() if k != 'total']\n",
    "    mode = max(freqs)\n",
    "    modes = [k for k,v in lengths.items() if v == mode]\n",
    "    coeff_variation = deviation/avg\n",
    "    print(label, \":\")\n",
    "    print('\\tavg: ', avg)\n",
    "    print('\\tstd_dev:', deviation)\n",
    "    print('\\tcoef_var:', coeff_variation)\n",
    "    print('\\tmin: ', min_len) \n",
    "    print('\\tmax: ', max_len)\n",
    "    print('\\tmode: ', mode, modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus building\n",
    "corpus = {}\n",
    "for row in training_df.itertuples():\n",
    "    words = row.article_words.split(',')\n",
    "    for word in words:\n",
    "        if word not in corpus:\n",
    "            corpus[word] = {}\n",
    "        if 'global' not in corpus[word]:\n",
    "            corpus[word]['global'] = 0\n",
    "        corpus[word]['global'] += 1\n",
    "        if row.topic not in corpus[word]:\n",
    "            corpus[word][row.topic] = 0\n",
    "        corpus[word][row.topic] += 1\n",
    "#print(corpus)\n",
    "\n",
    "for word, word_dist in corpus.items():\n",
    "    print(word)\n",
    "    for topic, freq in word_dist.items():\n",
    "        print('\\t', topic, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##look into entropy and all that jazz and do some statistics on the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
