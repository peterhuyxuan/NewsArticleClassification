{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming training set words to features with TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9500, 35822)\n",
      "0       FOREX MARKETS\n",
      "1       MONEY MARKETS\n",
      "2              SPORTS\n",
      "3       FOREX MARKETS\n",
      "4          IRRELEVANT\n",
      "            ...      \n",
      "9495          DEFENCE\n",
      "9496       IRRELEVANT\n",
      "9497    FOREX MARKETS\n",
      "9498       IRRELEVANT\n",
      "9499    FOREX MARKETS\n",
      "Name: topic, Length: 9500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv('training.csv')\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#give each word a tf-idf value\n",
    "train_features = vectorizer.fit_transform(df['article_words'])\n",
    "\n",
    "print(train_features.shape)\n",
    "\n",
    "# Set topics for the training set\n",
    "y_train = df['topic']\n",
    "\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming test set words to features with TF-IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 35822)\n",
      "0          IRRELEVANT\n",
      "1          IRRELEVANT\n",
      "2       FOREX MARKETS\n",
      "3          IRRELEVANT\n",
      "4          IRRELEVANT\n",
      "            ...      \n",
      "495        IRRELEVANT\n",
      "496            SPORTS\n",
      "497     MONEY MARKETS\n",
      "498    SHARE LISTINGS\n",
      "499        IRRELEVANT\n",
      "Name: topic, Length: 500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv('test.csv')\n",
    "\n",
    "#give each word a tf-idf value\n",
    "test_features = vectorizer.transform(df_test['article_words'])\n",
    "\n",
    "print(test_features.shape)\n",
    "\n",
    "# Set topics for the test set\n",
    "y_test = df_test['topic']\n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding hyper-tuning the Stochastic Gradient Descent to find the  best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='hinge', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5,\n",
       "                                     random_state=None, shuffle=False,\n",
       "                                     tol=0.001, validation_fraction=0.1,\n",
       "                                     verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'eta0': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12,\n",
       "                                  0.13, 0.14, 0.15],\n",
       "                         'learning_rate': ('constant', 'optimal'),\n",
       "                         'tol': (0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06, 1e-07,\n",
       "                                 1e-08)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setting up the parameters for hyper-tuning\n",
    "parameters = {\n",
    "                'tol': (1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8),\n",
    "                'learning_rate': ('constant', 'optimal'), \n",
    "                'eta0': [x * 0.01 for x in range(5, 16)]\n",
    "             }\n",
    "\n",
    "# Preventing the SGD Classifer from shuffling to keep values consistent\n",
    "sgd = linear_model.SGDClassifier(shuffle=False)\n",
    "\n",
    "# Using the default 5-fold cross-validation for hyper-tuning and fitting the classifier\n",
    "SGD_clf = GridSearchCV(sgd, parameters)\n",
    "SGD_clf.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV(cv=None, error_score=nan,\n",
    "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
    "                                     class_weight=None, early_stopping=False,\n",
    "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "                                     l1_ratio=0.15, learning_rate='optimal',\n",
    "                                     loss='hinge', max_iter=1000,\n",
    "                                     n_iter_no_change=5, n_jobs=None,\n",
    "                                     penalty='l2', power_t=0.5,\n",
    "                                     random_state=None, shuffle=False,\n",
    "                                     tol=0.001, validation_fraction=0.1,\n",
    "                                     verbose=0, warm_start=False),\n",
    "             iid='deprecated', n_jobs=None,\n",
    "             param_grid={'eta0': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12,\n",
    "                                  0.13, 0.14, 0.15],\n",
    "                         'learning_rate': ('constant', 'optimal'),\n",
    "                         'tol': (0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06, 1e-07,\n",
    "                                 1e-08)},\n",
    "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
    "             scoring=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.294770</td>\n",
       "      <td>0.041806</td>\n",
       "      <td>0.015891</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'eta0': 0.05, 'learning_rate': 'constant', 't...</td>\n",
       "      <td>0.755263</td>\n",
       "      <td>0.764737</td>\n",
       "      <td>0.762105</td>\n",
       "      <td>0.756316</td>\n",
       "      <td>0.751053</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.004915</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.306445</td>\n",
       "      <td>0.022210</td>\n",
       "      <td>0.016666</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'eta0': 0.05, 'learning_rate': 'constant', 't...</td>\n",
       "      <td>0.765263</td>\n",
       "      <td>0.768947</td>\n",
       "      <td>0.763684</td>\n",
       "      <td>0.767368</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>0.764842</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682532</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.013806</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'eta0': 0.05, 'learning_rate': 'constant', 't...</td>\n",
       "      <td>0.777895</td>\n",
       "      <td>0.775263</td>\n",
       "      <td>0.775263</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.135914</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'eta0': 0.05, 'learning_rate': 'constant', 't...</td>\n",
       "      <td>0.774211</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.782105</td>\n",
       "      <td>0.771579</td>\n",
       "      <td>0.774211</td>\n",
       "      <td>0.776421</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.715690</td>\n",
       "      <td>0.093014</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'eta0': 0.05, 'learning_rate': 'constant', 't...</td>\n",
       "      <td>0.774737</td>\n",
       "      <td>0.779474</td>\n",
       "      <td>0.782632</td>\n",
       "      <td>0.772632</td>\n",
       "      <td>0.774211</td>\n",
       "      <td>0.776737</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.429490</td>\n",
       "      <td>0.249383</td>\n",
       "      <td>0.017670</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'eta0': 0.15, 'learning_rate': 'optimal', 'to...</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.784737</td>\n",
       "      <td>0.771053</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.778421</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3.517115</td>\n",
       "      <td>0.690001</td>\n",
       "      <td>0.017817</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'eta0': 0.15, 'learning_rate': 'optimal', 'to...</td>\n",
       "      <td>0.776842</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.787368</td>\n",
       "      <td>0.772105</td>\n",
       "      <td>0.781053</td>\n",
       "      <td>0.779263</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>5.059753</td>\n",
       "      <td>0.504376</td>\n",
       "      <td>0.015058</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>{'eta0': 0.15, 'learning_rate': 'optimal', 'to...</td>\n",
       "      <td>0.776842</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.787368</td>\n",
       "      <td>0.772105</td>\n",
       "      <td>0.780526</td>\n",
       "      <td>0.779158</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>7.516248</td>\n",
       "      <td>1.387870</td>\n",
       "      <td>0.024220</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>{'eta0': 0.15, 'learning_rate': 'optimal', 'to...</td>\n",
       "      <td>0.776842</td>\n",
       "      <td>0.779474</td>\n",
       "      <td>0.787368</td>\n",
       "      <td>0.772105</td>\n",
       "      <td>0.780526</td>\n",
       "      <td>0.779263</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>5.607247</td>\n",
       "      <td>0.424926</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>{'eta0': 0.15, 'learning_rate': 'optimal', 'to...</td>\n",
       "      <td>0.776842</td>\n",
       "      <td>0.779474</td>\n",
       "      <td>0.787368</td>\n",
       "      <td>0.772105</td>\n",
       "      <td>0.780526</td>\n",
       "      <td>0.779263</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_eta0  \\\n",
       "0         0.294770      0.041806         0.015891        0.003538       0.05   \n",
       "1         0.306445      0.022210         0.016666        0.001715       0.05   \n",
       "2         0.682532      0.021429         0.013806        0.002863       0.05   \n",
       "3         2.135914      0.022121         0.014401        0.003458       0.05   \n",
       "4         3.715690      0.093014         0.014670        0.003411       0.05   \n",
       "..             ...           ...              ...             ...        ...   \n",
       "171       1.429490      0.249383         0.017670        0.007107       0.15   \n",
       "172       3.517115      0.690001         0.017817        0.004448       0.15   \n",
       "173       5.059753      0.504376         0.015058        0.001513       0.15   \n",
       "174       7.516248      1.387870         0.024220        0.009982       0.15   \n",
       "175       5.607247      0.424926         0.013057        0.002918       0.15   \n",
       "\n",
       "    param_learning_rate param_tol  \\\n",
       "0              constant       0.1   \n",
       "1              constant      0.01   \n",
       "2              constant     0.001   \n",
       "3              constant    0.0001   \n",
       "4              constant     1e-05   \n",
       "..                  ...       ...   \n",
       "171             optimal    0.0001   \n",
       "172             optimal     1e-05   \n",
       "173             optimal     1e-06   \n",
       "174             optimal     1e-07   \n",
       "175             optimal     1e-08   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'eta0': 0.05, 'learning_rate': 'constant', 't...           0.755263   \n",
       "1    {'eta0': 0.05, 'learning_rate': 'constant', 't...           0.765263   \n",
       "2    {'eta0': 0.05, 'learning_rate': 'constant', 't...           0.777895   \n",
       "3    {'eta0': 0.05, 'learning_rate': 'constant', 't...           0.774211   \n",
       "4    {'eta0': 0.05, 'learning_rate': 'constant', 't...           0.774737   \n",
       "..                                                 ...                ...   \n",
       "171  {'eta0': 0.15, 'learning_rate': 'optimal', 'to...           0.776316   \n",
       "172  {'eta0': 0.15, 'learning_rate': 'optimal', 'to...           0.776842   \n",
       "173  {'eta0': 0.15, 'learning_rate': 'optimal', 'to...           0.776842   \n",
       "174  {'eta0': 0.15, 'learning_rate': 'optimal', 'to...           0.776842   \n",
       "175  {'eta0': 0.15, 'learning_rate': 'optimal', 'to...           0.776842   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0             0.764737           0.762105           0.756316   \n",
       "1             0.768947           0.763684           0.767368   \n",
       "2             0.775263           0.775263           0.770000   \n",
       "3             0.780000           0.782105           0.771579   \n",
       "4             0.779474           0.782632           0.772632   \n",
       "..                 ...                ...                ...   \n",
       "171           0.780000           0.784737           0.771053   \n",
       "172           0.778947           0.787368           0.772105   \n",
       "173           0.778947           0.787368           0.772105   \n",
       "174           0.779474           0.787368           0.772105   \n",
       "175           0.779474           0.787368           0.772105   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.751053         0.757895        0.004915              176  \n",
       "1             0.758947         0.764842        0.003450              173  \n",
       "2             0.770000         0.773684        0.003158              126  \n",
       "3             0.774211         0.776421        0.003958               62  \n",
       "4             0.774211         0.776737        0.003728               59  \n",
       "..                 ...              ...             ...              ...  \n",
       "171           0.780000         0.778421        0.004552               45  \n",
       "172           0.781053         0.779263        0.005022                1  \n",
       "173           0.780526         0.779158        0.004989               34  \n",
       "174           0.780526         0.779263        0.004989                1  \n",
       "175           0.780526         0.779263        0.004989                1  \n",
       "\n",
       "[176 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the results of the cross-validation hyper-tuning\n",
    "df_SGD = pd.DataFrame(SGD_clf.cv_results_)\n",
    "df_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.764842</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.776421</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>constant</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.776737</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.778421</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.779263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>0.779158</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>0.779263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>0.779263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_eta0 param_learning_rate param_tol  mean_test_score  rank_test_score\n",
       "0         0.05            constant       0.1         0.757895              176\n",
       "1         0.05            constant      0.01         0.764842              173\n",
       "2         0.05            constant     0.001         0.773684              126\n",
       "3         0.05            constant    0.0001         0.776421               62\n",
       "4         0.05            constant     1e-05         0.776737               59\n",
       "..         ...                 ...       ...              ...              ...\n",
       "171       0.15             optimal    0.0001         0.778421               45\n",
       "172       0.15             optimal     1e-05         0.779263                1\n",
       "173       0.15             optimal     1e-06         0.779158               34\n",
       "174       0.15             optimal     1e-07         0.779263                1\n",
       "175       0.15             optimal     1e-08         0.779263                1\n",
       "\n",
       "[176 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtered out table with relevant changed parameers with their accuracy values\n",
    "df_SGD[['param_eta0', 'param_learning_rate', 'param_tol', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_eta0\tparam_learning_rate\tparam_tol\tmean_test_score\trank_test_score\n",
    "0\t0.05\tconstant\t0.1\t0.757895\t176\n",
    "1\t0.05\tconstant\t0.01\t0.764842\t173\n",
    "2\t0.05\tconstant\t0.001\t0.773684\t126\n",
    "3\t0.05\tconstant\t0.0001\t0.776421\t62\n",
    "4\t0.05\tconstant\t1e-05\t0.776737\t59\n",
    "...\t...\t...\t...\t...\t...\n",
    "171\t0.15\toptimal\t0.0001\t0.778421\t45\n",
    "172\t0.15\toptimal\t1e-05\t0.779263\t1\n",
    "173\t0.15\toptimal\t1e-06\t0.779158\t34\n",
    "174\t0.15\toptimal\t1e-07\t0.779263\t1\n",
    "175\t0.15\toptimal\t1e-08\t0.779263\t1\n",
    "176 rows × 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792631578947369"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD_clf.best_score_ = 0.7792631578947369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta0': 0.05, 'learning_rate': 'optimal', 'tol': 1e-05}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD_clf.best_params_ = \n",
    "{'eta0': 0.05, 'learning_rate': 'optimal', 'tol': 1e-05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.05, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=False, tol=1e-05,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD_clf.best_estimator_ = SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "              early_stopping=False, epsilon=0.1, eta0=0.05, fit_intercept=True,\n",
    "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
    "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "              power_t=0.5, random_state=None, shuffle=False, tol=1e-05,\n",
    "              validation_fraction=0.1, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning the best estimator as the new SGD Classifier with the best estimated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Assigning the existing saved SGD classifier best_estimator with the best parameters\n",
    "SGD_best_estimator = SGDClassifier(alpha=0.0001, average=False, class_weight=None, early_stopping=False, epsilon=0.1, eta0=0.05, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5, random_state=None, shuffle=False, tol=1e-05, validation_fraction=0.1, verbose=0, warm_start=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelining to find the best classifier between the Stochastic Gradient Descent and Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Setting up the pipeline for each classifier\n",
    "pipeline_SGD =Pipeline([\n",
    "    ('sgd_clf', SGD_best_estimator)])\n",
    "\n",
    "pipeline_MNB = Pipeline([\n",
    "    ('mnb_clf', MultinomialNB(fit_prior=False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising values\n",
    "pipelines = [pipeline_SGD, pipeline_MNB]\n",
    "best_accuracy=0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Stochastic Gradient Descent', 1: 'Multinomial Naive Bayes'}\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent Test Accuracy: 0.758\n",
      "Multinomial Naive Bayes Test Accuracy: 0.724\n"
     ]
    }
   ],
   "source": [
    "# Printing out the accuracy values for each classifier\n",
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(test_features,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy: Stochastic Gradient Descent\n"
     ]
    }
   ],
   "source": [
    "# Iterating through the pipelines to find the best classifier\n",
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(test_features,y_test)>best_accuracy:\n",
    "        best_accuracy=model.score(test_features,y_test)\n",
    "        best_pipeline=model\n",
    "        best_classifier=i\n",
    "print('Classifier with best accuracy: {}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning the best classifier with the best accuracy from the pipeline to calculate the top 10 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data accuracy: 0.758\n",
      "train data accuracy: 0.9022105263157895\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the best classifier from the pipeline and making the predictions\n",
    "best_clf = pipelines[best_classifier].steps[0][1]\n",
    "best_clf_prediction = best_clf.predict(test_features)\n",
    "print('test data accuracy: {}'.format(np.mean(best_clf_prediction == y_test)))\n",
    "\n",
    "best_clf_prediction_train = best_clf.predict(train_features)\n",
    "print('train data accuracy: {}'.format(np.mean(best_clf_prediction_train == y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "      ARTS CULTURE ENTERTAINMENT       0.33      0.67      0.44         3\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       1.00      0.20      0.33        15\n",
      "                         DEFENCE       0.88      0.54      0.67        13\n",
      "                DOMESTIC MARKETS       0.50      0.50      0.50         2\n",
      "                   FOREX MARKETS       0.41      0.27      0.33        48\n",
      "                          HEALTH       0.69      0.64      0.67        14\n",
      "                      IRRELEVANT       0.86      0.89      0.87       266\n",
      "                   MONEY MARKETS       0.52      0.68      0.59        69\n",
      "          SCIENCE AND TECHNOLOGY       0.00      0.00      0.00         3\n",
      "                  SHARE LISTINGS       0.40      0.29      0.33         7\n",
      "                          SPORTS       0.95      0.97      0.96        60\n",
      "\n",
      "                        accuracy                           0.76       500\n",
      "                       macro avg       0.59      0.51      0.52       500\n",
      "                    weighted avg       0.76      0.76      0.75       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, best_clf_prediction, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
